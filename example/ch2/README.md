# k-近邻算法

测量不同特征值之间的距离

## 优点： 精度搞、对异常值不敏感、无数据输入假定

## 缺点： 计算复杂度高、空间复杂度高

## 适用数据范围：数值型和标称型

kNN,原理：存在一个样本数据集合，也称作训练样本集，并且样本集中每个数据都存在标签，即我们知道样本集中每一数据与所属分类的对应关系。输入没有标签的新数据后，将新的数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本集中特征最相似数据（最近邻）的分类标签。一般来说，我们只选择样本数据集中前k个最相似的数据。通常k是不大于20的整数。最后，选择k个最相似数据中出现次数最多的分类，作为新数据的分类。

电影的打斗镜头数、接吻镜头数，类型评估

| 电影名称 | 打斗镜头数 | 接吻镜头数 | 电影类型 |
| --------- | --------- | --------- | --------- |
| California Man | 3 | 104 | 爱情片 |
| He's Not Really into Dudes | 2| 100 | 爱情片 |
| Beautiful Woman | 1 | 81 | 爱情片 |
| Kevin Longblade  | 101 | 10 | 动作片 |
| Robo Slayer | 99 | 5 | 动作片 |
| Amped | 98 | 2 | 动作片 |
| ? | 18 | 90 | 未知 |

k-近邻算法的一般流程

1. 收集数据：可以使用任何方法。
2. 准备数据：距离计算所需要的数值，最好是结构化的数据格式。
3. 分析数据：任何文本性的数据都可以使用图表进行可视化。
4. 训练算法：此步骤不适用于k-近邻算法。
5. 测试算法：计算距离，选择最近邻的数目k，并判断分类。
6. 使用算法：首先，需要输入一些数据，然后运行算法判定输入数据所属的分类，最后会输出一个分类结果。

缺少数据，未实现手写数字识别

